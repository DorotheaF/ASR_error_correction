import os
import jiwer
import string
import pandas as pd
from dotenv import load_dotenv, dotenv_values
from openai import OpenAI
def generate_corrections(transcript):
    # have it check if the edited utterance and utterance match exactly, and if not explain what error in the transcription is and why it occurred
    length_transcript = len(transcript)
    transcript = transcript[
        ["utterance_in_recording", "recordingID", "speaker", "transcript", "ASR", "WER", "confidence", "Ethnicity",
         "Race Description", "Personal Pronouns"]]
    transcript.insert(loc=10, column='corrected_utterance', value="")
    transcript = transcript.reset_index(drop=True)
    print(transcript.columns)

    for i in range(3, length_transcript - 3):
        print(str(i) + "/" + str(length_transcript))
        if not pd.isna(transcript.loc[i, 'ASR']) and str(transcript.loc[i, 'ASR']).strip() != "" and str(transcript.loc[i, 'ASR']).strip().lower() != "nan":
            utterance = " \n<middle> " + transcript.loc[i, 'speaker'] + ": " + transcript.loc[i, 'ASR'] + " </middle>\n"
            pre_context = ((transcript.loc[i - 3, 'speaker'] + ": " + transcript.loc[i - 3, 'ASR'] + " \n" +
                            transcript.loc[i - 2, 'speaker'] + ": " + transcript.loc[i - 2, 'ASR']) + " \n" +
                           transcript.loc[i - 1, 'speaker'] + ": " + transcript.loc[i - 1, 'ASR'])

            post_context = ((transcript.loc[i + 1, 'speaker'] + ": " + transcript.loc[i + 1, 'ASR'] + " \n" +
                             transcript.loc[i + 2, 'speaker'] + ": " + transcript.loc[i + 2, 'ASR']) + " \n" +
                            transcript.loc[i + 3, 'speaker'] + ": " + transcript.loc[i + 3, 'ASR'])

            messages = [
                {"role": "system", "content": """This is an excerpt from a discussion between tutors and students in a zoom classroom. The transcript was automatically generated by a speech recognition system. This system introduced errors into the transcription. This error significantly impacts downstream tasks, reducing accuracy and increasing bias. It is critical to KEEP mistakes that were originally made by the student or tutor, but CORRECT errors created by the speech recognition system."""},
                {"role": "user",
                 "content": "Here are 7 lines from the transcript and the audio file. Look at middle utterance and provided a corrected middle utterance, fixing any ASR system errors. Several lines of context are provided to help decide if the utterance was transcribed accurately, do not analyze errors in those lines. Give only the corrected sentence. \n ASR Transcript: \n "
                            + pre_context + utterance + post_context}
            ]

            print(utterance)
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )

            transcript.loc[i, "corrected_utterance"] = completion.choices[0].message.content

            print(transcript.loc[i, "corrected_utterance"])

    # transcript.to_excel("data/reasoning_generated/test_4o_generated_reasoning.xlsx", index=False)
    return transcript

        #TODO split response and save as columns
        # TODO generate WER for corrected and OG version

def calculate_wer(transcript):
    translator = str.maketrans('', '', string.punctuation)

    length_transcript = len(transcript)
    for i in range(3, length_transcript - 3):
        # print(str(i) + "/" + str(length_transcript))
        if not pd.isna(transcript.loc[i, 'ASR']) and str(transcript.loc[i, 'ASR']).strip() != "" and str(transcript.loc[i, 'ASR']).strip().lower() != "nan":
            reference = transcript.loc[i, 'transcript']
            hypothesis = transcript.loc[i, 'corrected_utterance']
            ASR_orig = transcript.loc[i, 'ASR']

            ref_clean = reference.lower().translate(translator)
            hyp_clean = hypothesis.lower().translate(translator)
            asr_clean = ASR_orig.lower().translate(translator)

            output_asr = jiwer.process_words(ref_clean, asr_clean)
            wer_asr = output_asr.wer

            transcript.loc[i, "ASR_recalc_WER"] = wer_asr

            output = jiwer.process_words(ref_clean, hyp_clean)
            wer = output.wer

            transcript.loc[i, "corrected_WER"] = wer
    return transcript



print("loading")

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI"))

# location = ""
location = "/mnt/c/Users/Dorot/Emotive Computing Dropbox/Dorothea French/ASR_error_correction/"



transcripts_test = ["ca7d9891-90a8-e7af-ba1b-3dd612d96456"] #delete ca7 file [ "e2e99d2e-845a-028a-e65c-854944a6de7d", "48a4fdd4-e68a-77f4-c8d9-35e6235b9199","1ee2c43c-8c28-cd1a-b970-0c0cf1a3918a","ee37c120-b375-4526-4721-279330a12d8e","d3a6871c-418d-1347-3895-cfb93458ba9b","ea380e6c-cd18-5965-2876-924bc0081f64","f5263c5d-d20d-edb1-58bc-1039c6290646","f865856f-6845-d71f-7062-d6f5159e3c38","18e87a02-3a52-3ed3-792a-7c935134b2a9",
                   # "40b254a6-1971-9e58-3b86-0d15bba60226","a0559b78-8dba-5875-01b0-dd3e9260d178","1c3fee41-c474-e57c-b6ec-261e8ba2261f","3962df1e-39f6-07e0-cfa5-bbac3ac9b3d4","289cff3c-07de-d3f6-a3fb-793ff3b35cd7","cafd96c5-7c5a-2668-4d37-2b149a548216","f94fa678-cff0-61e8-4dce-9f2294cfccb1","dafcae95-d017-934a-6075-9a414c4f7173","1670e2cf-cc9a-cccf-5aff-d89cfa2b4a4a","0394469c-492d-193a-e348-b6b1e230a37f"] #"75beca5b-c81c-3d10-e998-37035d39761d"

# tran_num = 0
# for file in transcripts_test:
#     print(tran_num)
#     tran_num += 1
#     file_name = location + "data/transcripts/" + file + ".xlsx"
#     transcript = pd.read_excel(file_name)
#     # transcript = transcript.dropna(subset=["ASR"])
#     transcript['ASR'] = transcript['ASR'].astype(str)
#     transcript_corrected = generate_corrections(transcript)
#     transcript_corrected.to_excel(location + "data/test_files/" + file + "_4omini_zeroshot_corrected.xlsx")

tran_num = 0
for file in transcripts_test:
    print(tran_num)
    tran_num += 1
    file_name = location + "data/test_files/" + file + "_4omini_zeroshot_corrected_not_in_test_set.xlsx"
    print(file_name)
    transcript = pd.read_excel(file_name)
    transcript['corrected_utterance'] = transcript['corrected_utterance'].astype(str)
    transcript['corrected_utterance'] = transcript['corrected_utterance'].apply(lambda x: x.split(":")[1] if str(x).strip().lower() != "nan" and ":" in x else x)
    transcript['transcript'] = transcript['transcript'].astype(str)
    transcript_corrected = calculate_wer(transcript)
    transcript_corrected.to_excel(location + "data/test_files/" + file + "_4omini_zeroshot_corrected_not_in_test_set.xlsx")


