import glob
import json
import os
import pandas as pd
# from unsloth import FastLanguageModel
import math
from dotenv import load_dotenv, dotenv_values
from openai import OpenAI


def generate_error_thinking_deepseek(transcript):
    #have it check if the edited utterance and utterance match exactly, and if not explain what error in the transcription is and why it occurred
    prompt_style = """
    ### Instruction:
    You are an expert annotator teaching a new annotator how to edit a transcript generated by speech recognition software.
    You know it is critical that they learn what kind of errors speech recognition systems will add to the transcript, 
    as opposed to the errors in the original human speech. The original error and speech style in these math tutoring 
    transcripts must be preserved so that researchers can understand how students and tutors talk with each other. 
    Here are 7 lines from the transcript. You have looked at the middle utterance and provided a corrected middle utterance,
    using your knowledge about speech recognition system errors. Now, teach the new annotator by walking through your 
    thought process. Start by repeating the <middle> and <corrected_middle> utterances to check if they match exactly. 
    If they do, explain why you think the ASR system got it perfectly correct instead of introducing errors. If they 
    differ, explain what the errors are in the <middle> utterance that you corrected in the <corrected_middle> utterance,
    and explain why the ASR system made those errors. Be concise. 

    ### ASR:
    <context> {} </context>
    <middle> {} </middle> 
    <context> {} </context>
    
    ### Corrected:
    <corrected_middle> {} </corrected_middle>
    
    ### Response:
    {}
    """
    FastLanguageModel.for_inference(model)

    length_transcript = len(transcript)
    transcript["Response"] = ""
    for i in range(3, length_transcript-3):
        print(i)
        utterance = transcript.iloc[i,3] + ": " + transcript.iloc[i,5]
        edited_utterance = transcript.iloc[i,3] + ": " + transcript.iloc[i,4]
        pre_context = ((transcript.iloc[i-3,3] + ": " + transcript.iloc[i-3,5] + "\n" +
                       transcript.iloc[i-2,3] + ": " + transcript.iloc[i-2,5]) + "\n" +
                       transcript.iloc[i-1,3] + ": " + transcript.iloc[i-1,5])

        post_context = ((transcript.iloc[i+1,3] + ": " + transcript.iloc[i+1,5] + "\n" +
                       transcript.iloc[i+2,3] + ": " + transcript.iloc[i+2,5]) + "\n" +
                       transcript.iloc[i+3,3] + ": " + transcript.iloc[i+3,5])

        input_text = prompt_style.format(pre_context, utterance,post_context, edited_utterance, "")

        inputs = tokenizer([input_text], return_tensors="pt").to("cuda")

        # print(input_text)

        outputs = model.generate(
            input_ids=inputs.input_ids,
            attention_mask=inputs.attention_mask,
            max_new_tokens=1200,
            use_cache=True,
        )
        response = tokenizer.batch_decode(outputs)
        print(response[0].split("### Response:")[1])


        transcript.iloc[i,11] = response[0].split("### Response:")[1]

        # Print the response
        # with open("test.txt", 'w') as file:
        #     file.write(response['message']['content'])

        # print(response['message']['content'])`
    return transcript

def generate_error_thinking_gpt4mini(transcript):
    # have it check if the edited utterance and utterance match exactly, and if not explain what error in the transcription is and why it occurred
    length_transcript = len(transcript)
    transcript = transcript[["utterance_in_recording", "recordingID", "speaker","transcript", "ASR", "WER", "confidence", "Ethnicity", "Race Description", "Personal Pronouns"]]
    transcript.insert(loc=10, column='Response', value="")
    transcript = transcript.reset_index(drop=True)
    print(transcript.columns)


    for i in range(3, length_transcript - 3):
        print(str(i) + "/" + str(length_transcript))
        edited_utterance = transcript.loc[i, 'speaker'] + ": " + transcript.loc[i, 'transcript']
        utterance =  " \n<middle> " + transcript.loc[i, 'speaker'] + ": " + transcript.loc[i, 'ASR']  + " </middle>\n"
        pre_context = ((transcript.loc[i - 3, 'speaker'] + ": " + transcript.loc[i - 3, 'ASR'] + " \n" +
                        transcript.loc[i - 2, 'speaker'] + ": " + transcript.loc[i - 2, 'ASR']) + " \n" +
                       transcript.loc[i - 1, 'speaker'] + ": " + transcript.loc[i - 1, 'ASR'])

        post_context = ((transcript.loc[i + 1, 'speaker'] + ": " + transcript.loc[i + 1, 'ASR'] + " \n" +
                         transcript.loc[i + 2, 'speaker'] + ": " + transcript.loc[i + 2, 'ASR']) + " \n" +
                        transcript.loc[i + 3, 'speaker'] + ": " + transcript.loc[i + 3, 'ASR'])

        messages = [
                {"role": "system", "content": """You are an expert annotator teaching a new annotator how to edit a transcript generated by speech recognition software.
                It is critical that they learn what kind of errors speech recognition systems add to the transcript, as opposed to the errors in the original human speech.
                The original error and speech style in these math tutoring transcripts must be preserved so that researchers can understand how students and tutors talk with each other.
                Speak in a chain of thought style, not as numbered points.
                Be concise."""},
                {"role": "user", "content": "Here are 7 lines from the transcript and the audio file. Look at middle utterance and provided a corrected middle utterance, fixing any ASR system errors. \n ASR Transcript: \n "
                 + pre_context + utterance + post_context},
                {"role": "assistant", "content": edited_utterance},
                {"role": "user", "content": """Now, teach the new annotator by walking through your thought process.
                If the corrected utterance is the same as the original, explain why you think the ASR system got it perfectly correct instead of introducing errors.
                If they differ, explain what the errors are in the <middle> utterance and why the ASR system made those errors.
                Follow up with an explanation of how you corrected them in the corrected middle utterance. """}
            ]

        print(utterance)
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages= messages
        )


        print(messages[1])

        transcript.loc[i, "Response"] = completion.choices[0].message.content
        #
        print(transcript.loc[i, "Response"])

    # transcript.to_excel("data/reasoning_generated/test_4o_generated_reasoning.xlsx", index=False)
    return transcript

def format_as_prompts(transcript):

    prompt_style_reasoning = """### Instruction:
    This is an excerpt from a discussion between tutors and students in a zoom classroom. The transcript was automatically generated by a speech recognition system. This system introduced errors into the transcription. This error significantly impacts downstream tasks, reducing accuracy and increasing bias. It is critical to KEEP mistakes that were originally made by the student or tutor, but CORRECT errors created by the speech recognition system. Here are 7 lines from the transcript. Look at the middle utterance and 1) print the utterance, 2) indicate if the utterance has one or more errors introduced by the speech recognition system, and 3) if there are introduced errors, what is the corrected sentence. Several lines of context are provided to help decide if the utterance was transcribed accurately, do not analyze errors in those lines. 

    ### ASR:
    <context> {} </context>
    <middle> {} </middle> 
    <context> {} </context>

    ### Response:
    <think>{} </think>
    1) {}
    2) {}
    3) {}
    """

    prompt_style_basic = """### Instruction:
    This is an excerpt from a discussion between tutors and students in a zoom classroom. The transcript was automatically generated by a speech recognition system. This system introduced errors into the transcription. This error significantly impacts downstream tasks, reducing accuracy and increasing bias. It is critical to KEEP mistakes that were originally made by the student or tutor, but CORRECT errors created by the speech recognition system. Here are 7 lines from the transcript. Look at the middle utterance and 1) print the utterance, 2) indicate if the utterance has one or more errors introduced by the speech recognition system, and 3) if there are introduced errors, what is the corrected sentence. Several lines of context are provided to help decide if the utterance was transcribed accurately, do not analyze errors in those lines. 

    ### ASR:
    <context> {} </context>
    <middle> {} </middle> 
    <context> {} </context>

    ### Response:
    1) {}
    2) {}
    3) {}
    """

    print(transcript.columns)

    length_transcript = len(transcript)
    training_prompt_reasoning = []
    training_prompt_basic = []
    ethnicity = transcript['Race Description'].values[0]
    for i in range(3, length_transcript - 3):
        # print(i)
        utterance = transcript.loc[i, 'speaker'] + ": " + transcript.loc[i, 'ASR']
        edited_utterance = transcript.loc[i, 'speaker'] + ": " + transcript.loc[i, 'transcript']
        pre_context = ((transcript.loc[i - 3, 'speaker'] + ": " + transcript.loc[i - 3, 'ASR'] + " \n" +
                        transcript.loc[i - 2, 'speaker'] + ": " + transcript.loc[i - 2, 'ASR']) + " \n" +
                       transcript.loc[i - 1, 'speaker'] + ": " + transcript.loc[i - 1, 'ASR'])

        print(transcript.loc[i + 1, 'ASR'])
        post_context = ((transcript.loc[i + 1, 'speaker'] + ": " + transcript.loc[i + 1, 'ASR'] + " \n" +
                         transcript.loc[i + 2, 'speaker'] + ": " + transcript.loc[i + 2, 'ASR']) + " \n" +
                        transcript.loc[i + 3, 'speaker'] + ": " + transcript.loc[i + 3, 'ASR'])

        if utterance == edited_utterance:
            errors = "There are no errors introduced by the ASR system"
            edited_utterance = "N/A"
        else:
            errors = "There are likely errors introduced by the ASR system"

        training_text = prompt_style_basic.format(pre_context, utterance, post_context, utterance,
                                                  errors, edited_utterance) + EOS_token
        training_prompt_basic.append(training_text)

        reasoning = transcript.loc[i, 'Response'] #.split("</think>")[-1].replace(EOS_token, "")

        training_text = prompt_style_reasoning.format(pre_context, utterance, post_context, reasoning, utterance, errors, edited_utterance) + EOS_token
        training_prompt_reasoning.append(training_text)

    return ethnicity, training_prompt_reasoning, training_prompt_basic


def generate_reasoning(location, save_path):
    print(location)
    transcripts = glob.glob(location + "*.xlsx")
    transcripts_finished = glob.glob(save_path + "*.xlsx")
    transcripts_finished = [x.rsplit("/",1)[1].split("_generated_reasoning.xlsx")[0] for x in transcripts_finished]
    # print(transcripts)
    # print(transcripts_finished)
    # print(len(transcripts))
    print(len(transcripts_finished))
    print(len(transcripts))


    for file in transcripts[0:len(transcripts)]:
        file_name = file.rsplit("/",1)[1].split(".xlsx")[0]
        if file_name not in transcripts_finished:
            print(file)
            transcript = pd.read_excel(file)
            transcript = transcript.dropna(subset=["ASR","transcript"])
            transcript['ASR'] = transcript['ASR'].astype(str)
            transcript['transcript'] = transcript['transcript'].astype(str)
            print(len(transcript))
            transcript_thinking = generate_error_thinking_gpt4mini(transcript)
            transcript_thinking.to_excel(save_path + file_name + "_generated_reasoning.xlsx", index=False)

def format_for_train(reasoning_path, train_save_path):
    print(reasoning_path)
    transcripts = glob.glob(reasoning_path + "*.xlsx")
    print(transcripts)
    print(len(transcripts))
    transcripts_test = ["e2e99d2e-845a-028a-e65c-854944a6de7d", "75beca5b-c81c-3d10-e998-37035d39761d","48a4fdd4-e68a-77f4-c8d9-35e6235b9199","1ee2c43c-8c28-cd1a-b970-0c0cf1a3918a","ee37c120-b375-4526-4721-279330a12d8e","d3a6871c-418d-1347-3895-cfb93458ba9b","ea380e6c-cd18-5965-2876-924bc0081f64","f5263c5d-d20d-edb1-58bc-1039c6290646","f865856f-6845-d71f-7062-d6f5159e3c38","18e87a02-3a52-3ed3-792a-7c935134b2a9",
                        "40b254a6-1971-9e58-3b86-0d15bba60226","a0559b78-8dba-5875-01b0-dd3e9260d178","1c3fee41-c474-e57c-b6ec-261e8ba2261f","3962df1e-39f6-07e0-cfa5-bbac3ac9b3d4","289cff3c-07de-d3f6-a3fb-793ff3b35cd7","cafd96c5-7c5a-2668-4d37-2b149a548216","f94fa678-cff0-61e8-4dce-9f2294cfccb1","dafcae95-d017-934a-6075-9a414c4f7173","1670e2cf-cc9a-cccf-5aff-d89cfa2b4a4a","0394469c-492d-193a-e348-b6b1e230a37f"]

    train_file_all = []
    train_file_white = []
    train_file_black = []

    i = 0
    tran_num = 0
    for file in transcripts:
        print(tran_num)
        tran_num += 1
        file_name = file.rsplit("/",1)[1].split("_generated_reasoning.xlsx")[0]
        if file_name not in transcripts_test:

            print(file)
            transcript = pd.read_excel(file)

            transcript['ASR'] = transcript['ASR'].astype(str)
            transcript['transcript'] = transcript['transcript'].astype(str)
            ethnicity, reasoning_prompts, basic_prompts = format_as_prompts(transcript)
            # transcript_formatted = transcript_formatted[transcript_formatted['training_prompt']!=""]
            # transcript_formatted_plain = transcript_formatted_plain[transcript_formatted_plain['training_prompt'] != ""]
            #TODO: check for null values & drop
            for j in range (0, len(reasoning_prompts)):
                details = {}
                details["text_reasoning"] = reasoning_prompts[j]
                details["text_basic"] = basic_prompts[j]
                details["file"] = file_name
                details["ethnicity"] = ethnicity
                if ethnicity == "Black or African American":
                    train_file_all.append(details)
                    train_file_black.append(details)
                elif ethnicity == "White":
                    train_file_white.append(details)
                    train_file_all.append(details)
                else:
                    train_file_all.append(details)
        else:
            i+=1


    with open(train_save_path + "all_train.json", "w") as outfile:
        outfile.write(json.dumps(train_file_all))
    with open(train_save_path + "black_train.json", "w") as outfile:
        outfile.write(json.dumps(train_file_black))
    with open(train_save_path + "white_train.json", "w") as outfile:
        outfile.write(json.dumps(train_file_white))
    print(i)




print("started")

location = "/mnt/c/Users/Dorot/Emotive Computing Dropbox/Dorothea French/ASR_error_correction/data/transcripts/"
save_path = "/mnt/c/Users/Dorot/Emotive Computing Dropbox/Dorothea French/ASR_error_correction/data/reasoning_generated/"
train_save_path = "/mnt/c/Users/Dorot/Emotive Computing Dropbox/Dorothea French/ASR_error_correction/data/train_files/"

# location = "data/transcripts/"
# save_path = "data/reasoning_generated/"

# location = "data/transcripts_no_reasoning/"
# save_path = "data/transcripts_no_reasoning/"

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI"))
#
# model, tokenizer = FastLanguageModel.from_pretrained(
#     # model_name = "unsloth/DeepSeek-R1-Distill-Qwen-32B-unsloth-bnb-4bit", #TODO
#     model_name = "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit",
#     max_seq_length = 2048, # Choose any for long context!
#     load_in_4bit = True,  # 4 bit quantization to reduce memory
#     load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory
#     full_finetuning = False, # [NEW!] We have full finetuning now!
#     # token = os.getenv("HUGGING_FACE"), # use one if using gated models #TODO
# )
# EOS_token = tokenizer.eos_token

print("loaded model")

generate_reasoning(location, save_path)
# format_for_train(save_path, train_save_path)
# make_mega_dataset("/mnt/c/Users/Dorot/Emotive Computing Dropbox/Dorothea French/ASR_error_correction/")

