import json
import random
import string

import jiwer
import pandas as pd
from unsloth import FastLanguageModel, FastModel
import torch
import os
from trl import SFTTrainer, SFTConfig
from datasets import load_dataset


def generate_corrections(transcript, name):
    prompt_style_test = """### Instruction:
    This is an excerpt from a discussion between tutors and students in a zoom classroom. The transcript was automatically generated by a speech recognition system. This system introduced errors into the transcription. This error significantly impacts downstream tasks, reducing accuracy and increasing bias. It is critical to KEEP mistakes that were originally made by the student or tutor, but CORRECT errors created by the speech recognition system. Here are 7 lines from the transcript. Look at the middle utterance and 1) print the utterance, 2) indicate if the utterance has one or more errors introduced by the speech recognition system, and 3) if there are introduced errors, what is the corrected sentence. Several lines of context are provided to help decide if the utterance was transcribed accurately, do not analyze errors in those lines. 

    ### ASR:
    <context> {} </context>
    <middle> {} </middle> 
    <context> {} </context>

    ### Response:
    """

    length_transcript = len(transcript)
    transcript["test_time_response"] = ""
    transcript["test_time_response"] = ""
    transcript["test_time_response"] = ""
    for i in range(3, length_transcript - 3):
        print(i)
        if not pd.isna(transcript.loc[i, 'ASR']) and str(transcript.loc[i, 'ASR']).strip() != "" and str(
                transcript.loc[i, 'ASR']).strip().lower() != "nan":
            utterance =  "\n<middle> " + transcript.loc[i, 'speaker'] + ": " + transcript.loc[i, 'ASR']  + " </middle>\n"
            pre_context = ((transcript.loc[i - 3, 'speaker'] + ": " + transcript.loc[i - 3, 'ASR'] + " \n" +
                            transcript.loc[i - 2, 'speaker'] + ": " + transcript.loc[i - 2, 'ASR']) + " \n" +
                           transcript.loc[i - 1, 'speaker'] + ": " + transcript.loc[i - 1, 'ASR'])

            post_context = ((transcript.loc[i + 1, 'speaker'] + ": " + transcript.loc[i + 1, 'ASR'] + " \n" +
                             transcript.loc[i + 2, 'speaker'] + ": " + transcript.loc[i + 2, 'ASR']) + " \n" +
                            transcript.loc[i + 3, 'speaker'] + ": " + transcript.loc[i + 3, 'ASR'])



            prompt = prompt_style_test.format(pre_context, utterance, post_context,"")

            input = tokenizer(prompt, return_tensors="pt").to("cuda")
            inpur = tokenizer(prompt, ).to
            output = model.generate(
                **input,
                max_new_tokens=2048,
                use_cache=False,
                # temperature=0.7,
                # top_p=0.8,
                # top_k=20,
                # min_p=0.0,
            )
            print("generated")
            print(tokenizer.decode(output[0], skip_special_tokens=True).split("### Response:")[1])
            transcript.loc[i, "test_time_response"] = tokenizer.decode(output[0], skip_special_tokens=True).split("### Response:")[1]
            if i % 50 == 0:
                transcript.to_excel(name)

    return transcript


        #TODO split response and save as columns
        # TODO generate WER for corrected and OG version



def calculate_wer(transcript):
    translator = str.maketrans('', '', string.punctuation)

    length_transcript = len(transcript)
    for i in range(3, length_transcript - 3):
        # print(str(i) + "/" + str(length_transcript))
        if not pd.isna(transcript.loc[i, 'ASR']) and str(transcript.loc[i, 'ASR']).strip() != "" and str(transcript.loc[i, 'ASR']).strip().lower() != "nan":
            reference = transcript.loc[i, 'transcript']
            hypothesis = transcript.loc[i, 'corrected_utterance']
            ASR_orig = transcript.loc[i, 'ASR']
            if ":" in hypothesis:
                hypothesis = hypothesis.split(":")[1]

            ref_clean = reference.lower().translate(translator)
            hyp_clean = hypothesis.lower().translate(translator)
            asr_clean = ASR_orig.lower().translate(translator)

            output_asr = jiwer.process_words(ref_clean, asr_clean)
            wer_asr = output_asr.wer

            transcript.loc[i, "ASR_recalc_WER"] = wer_asr

            output = jiwer.process_words(ref_clean, hyp_clean)
            wer = output.wer

            transcript.loc[i, "corrected_WER"] = wer
    return transcript


print("loading")

location = ""
# location = "/mnt/c/Users/Dorot/Emotive Computing Dropbox/Dorothea French/ASR_error_correction/"



transcripts_test = ["ca7d9891-90a8-e7af-ba1b-3dd612d96456"] #delete this file!, "e2e99d2e-845a-028a-e65c-854944a6de7d", "75beca5b-c81c-3d10-e998-37035d39761d","48a4fdd4-e68a-77f4-c8d9-35e6235b9199","1ee2c43c-8c28-cd1a-b970-0c0cf1a3918a","ee37c120-b375-4526-4721-279330a12d8e","d3a6871c-418d-1347-3895-cfb93458ba9b","ea380e6c-cd18-5965-2876-924bc0081f64","f5263c5d-d20d-edb1-58bc-1039c6290646","f865856f-6845-d71f-7062-d6f5159e3c38","18e87a02-3a52-3ed3-792a-7c935134b2a9",
                    #"40b254a6-1971-9e58-3b86-0d15bba60226","a0559b78-8dba-5875-01b0-dd3e9260d178","1c3fee41-c474-e57c-b6ec-261e8ba2261f","3962df1e-39f6-07e0-cfa5-bbac3ac9b3d4","289cff3c-07de-d3f6-a3fb-793ff3b35cd7","cafd96c5-7c5a-2668-4d37-2b149a548216","f94fa678-cff0-61e8-4dce-9f2294cfccb1","dafcae95-d017-934a-6075-9a414c4f7173","1670e2cf-cc9a-cccf-5aff-d89cfa2b4a4a","0394469c-492d-193a-e348-b6b1e230a37f"]

train_file_all = []
train_file_white = []
train_file_black = []

# tran_num = 0
model, tokenizer = FastModel.from_pretrained(
    model_name = "finetuned_deepseek32_all_reasoning",
    # model_name = "unsloth/DeepSeek-R1-Distill-Qwen-32B-unsloth-bnb-4bit",
    max_seq_length = 2048, # Choose any for long context!
    load_in_4bit = True,  # 4 bit quantization to reduce memory
    # token = os.getenv("HUGGING_FACE"), # use one if using gated models #TODO
)
FastLanguageModel.for_inference(model)
#
#
# for file in transcripts_test:
#     print(tran_num)
#     tran_num += 1
#     file_name = location + "data/transcripts/" + file + ".xlsx"
#     transcript = pd.read_excel(file_name)
#     transcript['ASR'] = transcript['ASR'].astype(str)
#     transcript_corrected = generate_corrections(transcript, location + "data/test_files/" + file + "_corrected.xlsx")
#     transcript_corrected.to_excel(location + "data/test_files/" + file + "_corrected.xlsx")

tran_num = 0
for file in transcripts_test:
    print(tran_num)
    tran_num += 1
    transcript = pd.read_excel(location + "data/test_files/" + file + "_corrected.xlsx")
    transcript['corrected_utterance'] = transcript['test_time_response'].apply(lambda x: x.split("3)")[1].split(":")[1] if str(x).strip().lower() != "nan" and "N/A" not in x.split("3)")[1] else x.split("2)")[0].split(":")[1] if str(x).strip().lower() != "nan" else x)
    transcript['corrected_utterance'] = transcript['corrected_utterance'].astype(str)
    transcript['transcript'] = transcript['transcript'].astype(str)
    transcript_corrected = calculate_wer(transcript)
    transcript_corrected.to_excel(location + "data/test_files/" + file + "_corrected.xlsx", index=False)
